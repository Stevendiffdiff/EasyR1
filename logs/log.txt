INFO 07-02 18:15:07 [__init__.py:244] Automatically detected platform cuda.
[36m(pid=111972)[0m WARNING 07-02 18:15:19 [env_override.py:17] NCCL_CUMEM_ENABLE is set to 0, skipping override. This may increase memory overhead with cudagraph+allreduce: https://github.com/NVIDIA/nccl/issues/1234
[36m(Runner pid=111972)[0m {
[36m(Runner pid=111972)[0m   "data": {
[36m(Runner pid=111972)[0m     "train_files": "hiyouga/geometry3k@train",
[36m(Runner pid=111972)[0m     "val_files": "hiyouga/geometry3k@test",
[36m(Runner pid=111972)[0m     "prompt_key": "problem",
[36m(Runner pid=111972)[0m     "answer_key": "answer",
[36m(Runner pid=111972)[0m     "image_key": "images",
[36m(Runner pid=111972)[0m     "video_key": "videos",
[36m(Runner pid=111972)[0m     "image_dir": null,
[36m(Runner pid=111972)[0m     "video_fps": 2.0,
[36m(Runner pid=111972)[0m     "max_prompt_length": 2048,
[36m(Runner pid=111972)[0m     "max_response_length": 2048,
[36m(Runner pid=111972)[0m     "rollout_batch_size": 512,
[36m(Runner pid=111972)[0m     "mini_rollout_batch_size": null,
[36m(Runner pid=111972)[0m     "val_batch_size": 1024,
[36m(Runner pid=111972)[0m     "format_prompt": "/root/EasyR1/examples/format_prompt/math.jinja",
[36m(Runner pid=111972)[0m     "override_chat_template": null,
[36m(Runner pid=111972)[0m     "shuffle": true,
[36m(Runner pid=111972)[0m     "seed": 1,
[36m(Runner pid=111972)[0m     "min_pixels": 262144,
[36m(Runner pid=111972)[0m     "max_pixels": 4194304,
[36m(Runner pid=111972)[0m     "filter_overlong_prompts": true,
[36m(Runner pid=111972)[0m     "filter_overlong_prompts_workers": 16
[36m(Runner pid=111972)[0m   },
[36m(Runner pid=111972)[0m   "worker": {
[36m(Runner pid=111972)[0m     "hybrid_engine": true,
[36m(Runner pid=111972)[0m     "actor": {
[36m(Runner pid=111972)[0m       "strategy": "fsdp",
[36m(Runner pid=111972)[0m       "global_batch_size": 128,
[36m(Runner pid=111972)[0m       "micro_batch_size_per_device_for_update": 4,
[36m(Runner pid=111972)[0m       "micro_batch_size_per_device_for_experience": 16,
[36m(Runner pid=111972)[0m       "max_grad_norm": 1.0,
[36m(Runner pid=111972)[0m       "clip_ratio_low": 0.2,
[36m(Runner pid=111972)[0m       "clip_ratio_high": 0.3,
[36m(Runner pid=111972)[0m       "clip_ratio_dual": 3.0,
[36m(Runner pid=111972)[0m       "loss_avg_mode": "token",
[36m(Runner pid=111972)[0m       "ppo_epochs": 1,
[36m(Runner pid=111972)[0m       "padding_free": true,
[36m(Runner pid=111972)[0m       "ulysses_size": 1,
[36m(Runner pid=111972)[0m       "use_torch_compile": true,
[36m(Runner pid=111972)[0m       "model": {
[36m(Runner pid=111972)[0m         "model_path": "/root/autodl-tmp/.autodl/model/Qwen/Qwen2.5-VL-3B-Instruct",
[36m(Runner pid=111972)[0m         "tokenizer_path": "/root/autodl-tmp/.autodl/model/Qwen/Qwen2.5-VL-3B-Instruct",
[36m(Runner pid=111972)[0m         "override_config": {},
[36m(Runner pid=111972)[0m         "enable_gradient_checkpointing": true,
[36m(Runner pid=111972)[0m         "trust_remote_code": false,
[36m(Runner pid=111972)[0m         "freeze_vision_tower": false
[36m(Runner pid=111972)[0m       },
[36m(Runner pid=111972)[0m       "optim": {
[36m(Runner pid=111972)[0m         "lr": 1e-06,
[36m(Runner pid=111972)[0m         "betas": [
[36m(Runner pid=111972)[0m           0.9,
[36m(Runner pid=111972)[0m           0.999
[36m(Runner pid=111972)[0m         ],
[36m(Runner pid=111972)[0m         "weight_decay": 0.01,
[36m(Runner pid=111972)[0m         "strategy": "adamw",
[36m(Runner pid=111972)[0m         "lr_warmup_ratio": 0.0,
[36m(Runner pid=111972)[0m         "lr_warmup_steps": null,
[36m(Runner pid=111972)[0m         "min_lr_ratio": null,
[36m(Runner pid=111972)[0m         "warmup_style": "constant",
[36m(Runner pid=111972)[0m         "training_steps": -1
[36m(Runner pid=111972)[0m       },
[36m(Runner pid=111972)[0m       "fsdp": {
[36m(Runner pid=111972)[0m         "enable_full_shard": true,
[36m(Runner pid=111972)[0m         "enable_cpu_offload": false,
[36m(Runner pid=111972)[0m         "enable_rank0_init": true,
[36m(Runner pid=111972)[0m         "use_orig_params": false,
[36m(Runner pid=111972)[0m         "torch_dtype": null,
[36m(Runner pid=111972)[0m         "fsdp_size": -1,
[36m(Runner pid=111972)[0m         "mp_param_dtype": "bf16",
[36m(Runner pid=111972)[0m         "mp_reduce_dtype": "fp32",
[36m(Runner pid=111972)[0m         "mp_buffer_dtype": "fp32"
[36m(Runner pid=111972)[0m       },
[36m(Runner pid=111972)[0m       "offload": {
[36m(Runner pid=111972)[0m         "offload_params": true,
[36m(Runner pid=111972)[0m         "offload_optimizer": true
[36m(Runner pid=111972)[0m       },
[36m(Runner pid=111972)[0m       "global_batch_size_per_device": -1,
[36m(Runner pid=111972)[0m       "disable_kl": false,
[36m(Runner pid=111972)[0m       "use_kl_loss": true,
[36m(Runner pid=111972)[0m       "kl_penalty": "low_var_kl",
[36m(Runner pid=111972)[0m       "kl_coef": 0.01
[36m(Runner pid=111972)[0m     },
[36m(Runner pid=111972)[0m     "critic": {
[36m(Runner pid=111972)[0m       "strategy": "fsdp",
[36m(Runner pid=111972)[0m       "global_batch_size": 256,
[36m(Runner pid=111972)[0m       "micro_batch_size_per_device_for_update": 4,
[36m(Runner pid=111972)[0m       "micro_batch_size_per_device_for_experience": 16,
[36m(Runner pid=111972)[0m       "max_grad_norm": 1.0,
[36m(Runner pid=111972)[0m       "cliprange_value": 0.5,
[36m(Runner pid=111972)[0m       "loss_avg_mode": "token",
[36m(Runner pid=111972)[0m       "ppo_epochs": 1,
[36m(Runner pid=111972)[0m       "padding_free": false,
[36m(Runner pid=111972)[0m       "ulysses_size": 1,
[36m(Runner pid=111972)[0m       "model": {
[36m(Runner pid=111972)[0m         "model_path": null,
[36m(Runner pid=111972)[0m         "tokenizer_path": null,
[36m(Runner pid=111972)[0m         "override_config": {},
[36m(Runner pid=111972)[0m         "enable_gradient_checkpointing": true,
[36m(Runner pid=111972)[0m         "trust_remote_code": true,
[36m(Runner pid=111972)[0m         "freeze_vision_tower": false
[36m(Runner pid=111972)[0m       },
[36m(Runner pid=111972)[0m       "optim": {
[36m(Runner pid=111972)[0m         "lr": 1e-06,
[36m(Runner pid=111972)[0m         "betas": [
[36m(Runner pid=111972)[0m           0.9,
[36m(Runner pid=111972)[0m           0.999
[36m(Runner pid=111972)[0m         ],
[36m(Runner pid=111972)[0m         "weight_decay": 0.01,
[36m(Runner pid=111972)[0m         "strategy": "adamw",
[36m(Runner pid=111972)[0m         "lr_warmup_ratio": 0.0,
[36m(Runner pid=111972)[0m         "lr_warmup_steps": null,
[36m(Runner pid=111972)[0m         "min_lr_ratio": null,
[36m(Runner pid=111972)[0m         "warmup_style": "constant",
[36m(Runner pid=111972)[0m         "training_steps": -1
[36m(Runner pid=111972)[0m       },
[36m(Runner pid=111972)[0m       "fsdp": {
[36m(Runner pid=111972)[0m         "enable_full_shard": true,
[36m(Runner pid=111972)[0m         "enable_cpu_offload": false,
[36m(Runner pid=111972)[0m         "enable_rank0_init": true,
[36m(Runner pid=111972)[0m         "use_orig_params": false,
[36m(Runner pid=111972)[0m         "torch_dtype": null,
[36m(Runner pid=111972)[0m         "fsdp_size": -1,
[36m(Runner pid=111972)[0m         "mp_param_dtype": "bf16",
[36m(Runner pid=111972)[0m         "mp_reduce_dtype": "fp32",
[36m(Runner pid=111972)[0m         "mp_buffer_dtype": "fp32"
[36m(Runner pid=111972)[0m       },
[36m(Runner pid=111972)[0m       "offload": {
[36m(Runner pid=111972)[0m         "offload_params": false,
[36m(Runner pid=111972)[0m         "offload_optimizer": false
[36m(Runner pid=111972)[0m       },
[36m(Runner pid=111972)[0m       "global_batch_size_per_device": -1
[36m(Runner pid=111972)[0m     },
[36m(Runner pid=111972)[0m     "ref": {
[36m(Runner pid=111972)[0m       "strategy": "fsdp",
[36m(Runner pid=111972)[0m       "fsdp": {
[36m(Runner pid=111972)[0m         "enable_full_shard": true,
[36m(Runner pid=111972)[0m         "enable_cpu_offload": true,
[36m(Runner pid=111972)[0m         "enable_rank0_init": true,
[36m(Runner pid=111972)[0m         "use_orig_params": false,
[36m(Runner pid=111972)[0m         "torch_dtype": null,
[36m(Runner pid=111972)[0m         "fsdp_size": -1,
[36m(Runner pid=111972)[0m         "mp_param_dtype": "bf16",
[36m(Runner pid=111972)[0m         "mp_reduce_dtype": "fp32",
[36m(Runner pid=111972)[0m         "mp_buffer_dtype": "fp32"
[36m(Runner pid=111972)[0m       },
[36m(Runner pid=111972)[0m       "offload": {
[36m(Runner pid=111972)[0m         "offload_params": false,
[36m(Runner pid=111972)[0m         "offload_optimizer": false
[36m(Runner pid=111972)[0m       },
[36m(Runner pid=111972)[0m       "micro_batch_size_per_device_for_experience": 16,
[36m(Runner pid=111972)[0m       "padding_free": true,
[36m(Runner pid=111972)[0m       "ulysses_size": 1,
[36m(Runner pid=111972)[0m       "use_torch_compile": true
[36m(Runner pid=111972)[0m     },
[36m(Runner pid=111972)[0m     "reward": {
[36m(Runner pid=111972)[0m       "reward_type": "batch",
[36m(Runner pid=111972)[0m       "reward_function": "/root/EasyR1/examples/reward_function/math.py",
[36m(Runner pid=111972)[0m       "reward_function_kwargs": {},
[36m(Runner pid=111972)[0m       "skip_special_tokens": true,
[36m(Runner pid=111972)[0m       "num_cpus": 1,
[36m(Runner pid=111972)[0m       "reward_function_name": "compute_score"
[36m(Runner pid=111972)[0m     },
[36m(Runner pid=111972)[0m     "rollout": {
[36m(Runner pid=111972)[0m       "name": "vllm",
[36m(Runner pid=111972)[0m       "n": 5,
[36m(Runner pid=111972)[0m       "temperature": 1.0,
[36m(Runner pid=111972)[0m       "top_p": 0.99,
[36m(Runner pid=111972)[0m       "top_k": -1,
[36m(Runner pid=111972)[0m       "seed": 1,
[36m(Runner pid=111972)[0m       "limit_images": 0,
[36m(Runner pid=111972)[0m       "dtype": "bf16",
[36m(Runner pid=111972)[0m       "gpu_memory_utilization": 0.6,
[36m(Runner pid=111972)[0m       "ignore_eos": false,
[36m(Runner pid=111972)[0m       "enforce_eager": false,
[36m(Runner pid=111972)[0m       "enable_chunked_prefill": false,
[36m(Runner pid=111972)[0m       "tensor_parallel_size": 1,
[36m(Runner pid=111972)[0m       "max_model_len": null,
[36m(Runner pid=111972)[0m       "max_num_batched_tokens": 8192,
[36m(Runner pid=111972)[0m       "disable_log_stats": true,
[36m(Runner pid=111972)[0m       "disable_tqdm": false,
[36m(Runner pid=111972)[0m       "val_override_config": {
[36m(Runner pid=111972)[0m         "temperature": 0.5,
[36m(Runner pid=111972)[0m         "n": 1
[36m(Runner pid=111972)[0m       },
[36m(Runner pid=111972)[0m       "prompt_length": 2048,
[36m(Runner pid=111972)[0m       "response_length": 2048,
[36m(Runner pid=111972)[0m       "trust_remote_code": false
[36m(Runner pid=111972)[0m     }
[36m(Runner pid=111972)[0m   },
[36m(Runner pid=111972)[0m   "algorithm": {
[36m(Runner pid=111972)[0m     "gamma": 1.0,
[36m(Runner pid=111972)[0m     "lam": 1.0,
[36m(Runner pid=111972)[0m     "adv_estimator": "grpo",
[36m(Runner pid=111972)[0m     "disable_kl": false,
[36m(Runner pid=111972)[0m     "use_kl_loss": true,
[36m(Runner pid=111972)[0m     "kl_penalty": "low_var_kl",
[36m(Runner pid=111972)[0m     "kl_coef": 0.01,
[36m(Runner pid=111972)[0m     "kl_type": "fixed",
[36m(Runner pid=111972)[0m     "kl_horizon": 10000.0,
[36m(Runner pid=111972)[0m     "kl_target": 0.1,
[36m(Runner pid=111972)[0m     "online_filtering": false,
[36m(Runner pid=111972)[0m     "filter_key": "overall",
[36m(Runner pid=111972)[0m     "filter_low": 0.01,
[36m(Runner pid=111972)[0m     "filter_high": 0.99
[36m(Runner pid=111972)[0m   },
[36m(Runner pid=111972)[0m   "trainer": {
[36m(Runner pid=111972)[0m     "total_epochs": 15,
[36m(Runner pid=111972)[0m     "max_steps": null,
[36m(Runner pid=111972)[0m     "project_name": "easy_r1",
[36m(Runner pid=111972)[0m     "experiment_name": "qwen2_5_vl_3b_geo_grpo",
[36m(Runner pid=111972)[0m     "logger": [
[36m(Runner pid=111972)[0m       "console"
[36m(Runner pid=111972)[0m     ],
[36m(Runner pid=111972)[0m     "nnodes": 1,
[36m(Runner pid=111972)[0m     "n_gpus_per_node": 2,
[36m(Runner pid=111972)[0m     "max_try_make_batch": 20,
[36m(Runner pid=111972)[0m     "critic_warmup": 0,
[36m(Runner pid=111972)[0m     "val_freq": 5,
[36m(Runner pid=111972)[0m     "val_before_train": true,
[36m(Runner pid=111972)[0m     "val_only": false,
[36m(Runner pid=111972)[0m     "val_generations_to_log": 3,
[36m(Runner pid=111972)[0m     "save_freq": 5,
[36m(Runner pid=111972)[0m     "save_limit": 3,
[36m(Runner pid=111972)[0m     "save_model_only": false,
[36m(Runner pid=111972)[0m     "save_checkpoint_path": "/root/EasyR1/checkpoints/easy_r1/qwen2_5_vl_3b_geo_grpo",
[36m(Runner pid=111972)[0m     "load_checkpoint_path": null
[36m(Runner pid=111972)[0m   }
[36m(Runner pid=111972)[0m }
[36m(BatchFunctionRewardManager pid=112365)[0m Using reward function `compute_score` from `/root/EasyR1/examples/reward_function/math.py`.
[36m(Runner pid=111972)[0m Size of train dataloader: 4
[36m(Runner pid=111972)[0m Size of val dataloader: 1
[36m(Runner pid=111972)[0m Total training steps: 60
[36m(BatchFunctionRewardManager pid=112398)[0m Using reward function `compute_score` from `/root/EasyR1/examples/reward_function/math.py`.
[36m(pid=114974)[0m WARNING 07-02 18:15:47 [env_override.py:17] NCCL_CUMEM_ENABLE is set to 0, skipping override. This may increase memory overhead with cudagraph+allreduce: https://github.com/NVIDIA/nccl/issues/1234
[36m(pid=115355)[0m WARNING 07-02 18:15:56 [env_override.py:17] NCCL_CUMEM_ENABLE is set to 0, skipping override. This may increase memory overhead with cudagraph+allreduce: https://github.com/NVIDIA/nccl/issues/1234
[36m(WorkerDict pid=114974)[0m actor will use global batch size 640.
[36m(WorkerDict pid=114974)[0m Model config: Qwen2_5_VLConfig {
[36m(WorkerDict pid=114974)[0m   "architectures": [
[36m(WorkerDict pid=114974)[0m     "Qwen2_5_VLForConditionalGeneration"
[36m(WorkerDict pid=114974)[0m   ],
[36m(WorkerDict pid=114974)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=114974)[0m   "eos_token_id": 151645,
[36m(WorkerDict pid=114974)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=114974)[0m   "hidden_size": 2048,
[36m(WorkerDict pid=114974)[0m   "image_token_id": 151655,
[36m(WorkerDict pid=114974)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=114974)[0m   "intermediate_size": 11008,
[36m(WorkerDict pid=114974)[0m   "max_position_embeddings": 128000,
[36m(WorkerDict pid=114974)[0m   "max_window_layers": 70,
[36m(WorkerDict pid=114974)[0m   "model_type": "qwen2_5_vl",
[36m(WorkerDict pid=114974)[0m   "num_attention_heads": 16,
[36m(WorkerDict pid=114974)[0m   "num_hidden_layers": 36,
[36m(WorkerDict pid=114974)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=114974)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=114974)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=114974)[0m   "rope_scaling": {
[36m(WorkerDict pid=114974)[0m     "mrope_section": [
[36m(WorkerDict pid=114974)[0m       16,
[36m(WorkerDict pid=114974)[0m       24,
[36m(WorkerDict pid=114974)[0m       24
[36m(WorkerDict pid=114974)[0m     ],
[36m(WorkerDict pid=114974)[0m     "rope_type": "default",
[36m(WorkerDict pid=114974)[0m     "type": "default"
[36m(WorkerDict pid=114974)[0m   },
[36m(WorkerDict pid=114974)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=114974)[0m   "sliding_window": 32768,
[36m(WorkerDict pid=114974)[0m   "text_config": {
[36m(WorkerDict pid=114974)[0m     "architectures": [
[36m(WorkerDict pid=114974)[0m       "Qwen2_5_VLForConditionalGeneration"
[36m(WorkerDict pid=114974)[0m     ],
[36m(WorkerDict pid=114974)[0m     "attention_dropout": 0.0,
[36m(WorkerDict pid=114974)[0m     "bos_token_id": 151643,
[36m(WorkerDict pid=114974)[0m     "eos_token_id": 151645,
[36m(WorkerDict pid=114974)[0m     "hidden_act": "silu",
[36m(WorkerDict pid=114974)[0m     "hidden_size": 2048,
[36m(WorkerDict pid=114974)[0m     "image_token_id": null,
[36m(WorkerDict pid=114974)[0m     "initializer_range": 0.02,
[36m(WorkerDict pid=114974)[0m     "intermediate_size": 11008,
[36m(WorkerDict pid=114974)[0m     "max_position_embeddings": 128000,
[36m(WorkerDict pid=114974)[0m     "max_window_layers": 70,
[36m(WorkerDict pid=114974)[0m     "model_type": "qwen2_5_vl_text",
[36m(WorkerDict pid=114974)[0m     "num_attention_heads": 16,
[36m(WorkerDict pid=114974)[0m     "num_hidden_layers": 36,
[36m(WorkerDict pid=114974)[0m     "num_key_value_heads": 2,
[36m(WorkerDict pid=114974)[0m     "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=114974)[0m     "rope_scaling": {
[36m(WorkerDict pid=114974)[0m       "mrope_section": [
[36m(WorkerDict pid=114974)[0m         16,
[36m(WorkerDict pid=114974)[0m         24,
[36m(WorkerDict pid=114974)[0m         24
[36m(WorkerDict pid=114974)[0m       ],
[36m(WorkerDict pid=114974)[0m       "rope_type": "default",
[36m(WorkerDict pid=114974)[0m       "type": "default"
[36m(WorkerDict pid=114974)[0m     },
[36m(WorkerDict pid=114974)[0m     "rope_theta": 1000000.0,
[36m(WorkerDict pid=114974)[0m     "sliding_window": 32768,
[36m(WorkerDict pid=114974)[0m     "tie_word_embeddings": true,
[36m(WorkerDict pid=114974)[0m     "torch_dtype": "bfloat16",
[36m(WorkerDict pid=114974)[0m     "use_cache": true,
[36m(WorkerDict pid=114974)[0m     "use_sliding_window": false,
[36m(WorkerDict pid=114974)[0m     "video_token_id": null,
[36m(WorkerDict pid=114974)[0m     "vision_end_token_id": 151653,
[36m(WorkerDict pid=114974)[0m     "vision_start_token_id": 151652,
[36m(WorkerDict pid=114974)[0m     "vision_token_id": 151654,
[36m(WorkerDict pid=114974)[0m     "vocab_size": 151936
[36m(WorkerDict pid=114974)[0m   },
[36m(WorkerDict pid=114974)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=114974)[0m   "transformers_version": "4.52.4",
[36m(WorkerDict pid=114974)[0m   "use_cache": true,
[36m(WorkerDict pid=114974)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=114974)[0m   "video_token_id": 151656,
[36m(WorkerDict pid=114974)[0m   "vision_config": {
[36m(WorkerDict pid=114974)[0m     "depth": 32,
[36m(WorkerDict pid=114974)[0m     "fullatt_block_indexes": [
[36m(WorkerDict pid=114974)[0m       7,
[36m(WorkerDict pid=114974)[0m       15,
[36m(WorkerDict pid=114974)[0m       23,
[36m(WorkerDict pid=114974)[0m       31
[36m(WorkerDict pid=114974)[0m     ],
[36m(WorkerDict pid=114974)[0m     "hidden_act": "silu",
[36m(WorkerDict pid=114974)[0m     "hidden_size": 1280,
[36m(WorkerDict pid=114974)[0m     "in_channels": 3,
[36m(WorkerDict pid=114974)[0m     "in_chans": 3,
[36m(WorkerDict pid=114974)[0m     "initializer_range": 0.02,
[36m(WorkerDict pid=114974)[0m     "intermediate_size": 3420,
[36m(WorkerDict pid=114974)[0m     "model_type": "qwen2_5_vl",
[36m(WorkerDict pid=114974)[0m     "num_heads": 16,
[36m(WorkerDict pid=114974)[0m     "out_hidden_size": 2048,
[36m(WorkerDict pid=114974)[0m     "patch_size": 14,
[36m(WorkerDict pid=114974)[0m     "spatial_merge_size": 2,
[36m(WorkerDict pid=114974)[0m     "spatial_patch_size": 14,
[36m(WorkerDict pid=114974)[0m     "temporal_patch_size": 2,
[36m(WorkerDict pid=114974)[0m     "tokens_per_second": 2,
[36m(WorkerDict pid=114974)[0m     "window_size": 112
[36m(WorkerDict pid=114974)[0m   },
[36m(WorkerDict pid=114974)[0m   "vision_end_token_id": 151653,
[36m(WorkerDict pid=114974)[0m   "vision_start_token_id": 151652,
[36m(WorkerDict pid=114974)[0m   "vision_token_id": 151654,
[36m(WorkerDict pid=114974)[0m   "vocab_size": 151936
[36m(WorkerDict pid=114974)[0m }
[36m(WorkerDict pid=114974)[0m 
[36m(WorkerDict pid=114974)[0m Ulysses patch applied!
[36m(WorkerDict pid=114974)[0m NCCL version 2.26.2+cuda12.2
[36m(WorkerDict pid=114974)[0m Qwen2_5_VLForConditionalGeneration contains 3.75B parameters.
[36m(WorkerDict pid=114974)[0m After huggingface model init: 0.56 GB / 23.53 GB.
[36m(WorkerDict pid=114974)[0m FSDP wrap policy: functools.partial(<function transformer_auto_wrap_policy at 0x7f84b3e789d0>, transformer_layer_cls={<class 'transformers.models.qwen2_5_vl.modeling_qwen2_5_vl.Qwen2_5_VLVisionBlock'>, <class 'transformers.models.qwen2_5_vl.modeling_qwen2_5_vl.Qwen2_5_VLDecoderLayer'>}).
[36m(WorkerDict pid=114974)[0m After FSDP module init: 10.78 GB / 23.53 GB.
[36m(WorkerDict pid=114974)[0m After optimizer init: 10.78 GB / 23.53 GB.
[36m(WorkerDict pid=114974)[0m After offload actor model during init: 0.59 GB / 23.53 GB.
[36m(WorkerDict pid=114974)[0m After offload actor optimizer during init: 0.59 GB / 23.53 GB.
[36m(WorkerDict pid=114974)[0m Ulysses patch applied!
[36m(WorkerDict pid=114974)[0m Qwen2_5_VLForConditionalGeneration contains 3.75B parameters.
[36m(WorkerDict pid=114974)[0m After huggingface model init: 0.59 GB / 23.53 GB.
[36m(WorkerDict pid=114974)[0m FSDP wrap policy: functools.partial(<function transformer_auto_wrap_policy at 0x7f84b3e789d0>, transformer_layer_cls={<class 'transformers.models.qwen2_5_vl.modeling_qwen2_5_vl.Qwen2_5_VLVisionBlock'>, <class 'transformers.models.qwen2_5_vl.modeling_qwen2_5_vl.Qwen2_5_VLDecoderLayer'>}).
[36m(WorkerDict pid=114974)[0m After FSDP module init: 2.61 GB / 23.53 GB.
[36m(WorkerDict pid=115355)[0m WARNING 07-02 18:16:25 [utils.py:2737] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f3060224310>
[36m(WorkerDict pid=114974)[0m WARNING 07-02 18:16:32 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[36m(WorkerDict pid=114974)[0m WARNING 07-02 18:16:26 [utils.py:2737] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f8298b80e50>
[36m(WorkerDict pid=114974)[0m Sampling params: {'max_tokens': 2048, 'detokenize': False, 'logit_bias': {151655: -100}, 'n': 5, 'temperature': 1.0, 'top_p': 0.99, 'top_k': -1, 'seed': 1, 'ignore_eos': False}.
[36m(WorkerDict pid=114974)[0m After vllm init: 1.61 GB / 23.53 GB.
[36m(WorkerDict pid=115355)[0m WARNING 07-02 18:16:32 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[36m(Runner pid=111972)[0m Config
[36m(Runner pid=111972)[0m algorithm:
[36m(Runner pid=111972)[0m   adv_estimator: grpo
[36m(Runner pid=111972)[0m   disable_kl: false
[36m(Runner pid=111972)[0m   filter_high: 0.99
[36m(Runner pid=111972)[0m   filter_key: overall
[36m(Runner pid=111972)[0m   filter_low: 0.01
[36m(Runner pid=111972)[0m   gamma: 1.0
[36m(Runner pid=111972)[0m   kl_coef: 0.01
[36m(Runner pid=111972)[0m   kl_horizon: 10000.0
[36m(Runner pid=111972)[0m   kl_penalty: low_var_kl
[36m(Runner pid=111972)[0m   kl_target: 0.1
[36m(Runner pid=111972)[0m   kl_type: fixed
[36m(Runner pid=111972)[0m   lam: 1.0
[36m(Runner pid=111972)[0m   online_filtering: false
[36m(Runner pid=111972)[0m   use_kl_loss: true
[36m(Runner pid=111972)[0m data:
[36m(Runner pid=111972)[0m   answer_key: answer
[36m(Runner pid=111972)[0m   filter_overlong_prompts: true
[36m(Runner pid=111972)[0m   filter_overlong_prompts_workers: 16
[36m(Runner pid=111972)[0m   format_prompt: /root/EasyR1/examples/format_prompt/math.jinja
[36m(Runner pid=111972)[0m   image_dir: null
[36m(Runner pid=111972)[0m   image_key: images
[36m(Runner pid=111972)[0m   max_pixels: 4194304
[36m(Runner pid=111972)[0m   max_prompt_length: 2048
[36m(Runner pid=111972)[0m   max_response_length: 2048
[36m(Runner pid=111972)[0m   min_pixels: 262144
[36m(Runner pid=111972)[0m   mini_rollout_batch_size: null
[36m(Runner pid=111972)[0m   override_chat_template: null
[36m(Runner pid=111972)[0m   prompt_key: problem
[36m(Runner pid=111972)[0m   rollout_batch_size: 512
[36m(Runner pid=111972)[0m   seed: 1
[36m(Runner pid=111972)[0m   shuffle: true
[36m(Runner pid=111972)[0m   train_files: hiyouga/geometry3k@train
[36m(Runner pid=111972)[0m   val_batch_size: 1024
[36m(Runner pid=111972)[0m   val_files: hiyouga/geometry3k@test
[36m(Runner pid=111972)[0m   video_fps: 2.0
[36m(Runner pid=111972)[0m   video_key: videos
[36m(Runner pid=111972)[0m trainer:
[36m(Runner pid=111972)[0m   critic_warmup: 0
[36m(Runner pid=111972)[0m   experiment_name: qwen2_5_vl_3b_geo_grpo
[36m(Runner pid=111972)[0m   load_checkpoint_path: null
[36m(Runner pid=111972)[0m   logger:
[36m(Runner pid=111972)[0m   - console
[36m(Runner pid=111972)[0m   max_steps: null
[36m(Runner pid=111972)[0m   max_try_make_batch: 20
[36m(Runner pid=111972)[0m   n_gpus_per_node: 2
[36m(Runner pid=111972)[0m   nnodes: 1
[36m(Runner pid=111972)[0m   project_name: easy_r1
[36m(Runner pid=111972)[0m   save_checkpoint_path: /root/EasyR1/checkpoints/easy_r1/qwen2_5_vl_3b_geo_grpo
[36m(Runner pid=111972)[0m   save_freq: 5
[36m(Runner pid=111972)[0m   save_limit: 3
[36m(Runner pid=111972)[0m   save_model_only: false
[36m(Runner pid=111972)[0m   total_epochs: 15
[36m(Runner pid=111972)[0m   val_before_train: true
[36m(Runner pid=111972)[0m   val_freq: 5
[36m(Runner pid=111972)[0m   val_generations_to_log: 3
[36m(Runner pid=111972)[0m   val_only: false
[36m(Runner pid=111972)[0m worker:
[36m(Runner pid=111972)[0m   actor:
[36m(Runner pid=111972)[0m     clip_ratio_dual: 3.0
[36m(Runner pid=111972)[0m     clip_ratio_high: 0.3
[36m(Runner pid=111972)[0m     clip_ratio_low: 0.2
[36m(Runner pid=111972)[0m     disable_kl: false
[36m(Runner pid=111972)[0m     fsdp:
[36m(Runner pid=111972)[0m       enable_cpu_offload: false
[36m(Runner pid=111972)[0m       enable_full_shard: true
[36m(Runner pid=111972)[0m       enable_rank0_init: true
[36m(Runner pid=111972)[0m       fsdp_size: -1
[36m(Runner pid=111972)[0m       mp_buffer_dtype: fp32
[36m(Runner pid=111972)[0m       mp_param_dtype: bf16
[36m(Runner pid=111972)[0m       mp_reduce_dtype: fp32
[36m(Runner pid=111972)[0m       torch_dtype: null
[36m(Runner pid=111972)[0m       use_orig_params: false
[36m(Runner pid=111972)[0m     global_batch_size: 128
[36m(Runner pid=111972)[0m     global_batch_size_per_device: -1
[36m(Runner pid=111972)[0m     kl_coef: 0.01
[36m(Runner pid=111972)[0m     kl_penalty: low_var_kl
[36m(Runner pid=111972)[0m     loss_avg_mode: token
[36m(Runner pid=111972)[0m     max_grad_norm: 1.0
[36m(Runner pid=111972)[0m     micro_batch_size_per_device_for_experience: 16
[36m(Runner pid=111972)[0m     micro_batch_size_per_device_for_update: 4
[36m(Runner pid=111972)[0m     model:
[36m(Runner pid=111972)[0m       enable_gradient_checkpointing: true
[36m(Runner pid=111972)[0m       freeze_vision_tower: false
[36m(Runner pid=111972)[0m       model_path: /root/autodl-tmp/.autodl/model/Qwen/Qwen2.5-VL-3B-Instruct
[36m(Runner pid=111972)[0m       override_config: {}
[36m(Runner pid=111972)[0m       tokenizer_path: /root/autodl-tmp/.autodl/model/Qwen/Qwen2.5-VL-3B-Instruct
[36m(Runner pid=111972)[0m       trust_remote_code: false
[36m(Runner pid=111972)[0m     offload:
[36m(Runner pid=111972)[0m       offload_optimizer: true
[36m(Runner pid=111972)[0m       offload_params: true
[36m(Runner pid=111972)[0m     optim:
[36m(Runner pid=111972)[0m       betas:
[36m(Runner pid=111972)[0m       - 0.9
[36m(Runner pid=111972)[0m       - 0.999
[36m(Runner pid=111972)[0m       lr: 1.0e-06
[36m(Runner pid=111972)[0m       lr_warmup_ratio: 0.0
[36m(Runner pid=111972)[0m       lr_warmup_steps: null
[36m(Runner pid=111972)[0m       min_lr_ratio: null
[36m(Runner pid=111972)[0m       strategy: adamw
[36m(Runner pid=111972)[0m       training_steps: 60
[36m(Runner pid=111972)[0m       warmup_style: constant
[36m(Runner pid=111972)[0m       weight_decay: 0.01
[36m(Runner pid=111972)[0m     padding_free: true
[36m(Runner pid=111972)[0m     ppo_epochs: 1
[36m(Runner pid=111972)[0m     strategy: fsdp
[36m(Runner pid=111972)[0m     ulysses_size: 1
[36m(Runner pid=111972)[0m     use_kl_loss: true
[36m(Runner pid=111972)[0m     use_torch_compile: true
[36m(Runner pid=111972)[0m   critic:
[36m(Runner pid=111972)[0m     cliprange_value: 0.5
[36m(Runner pid=111972)[0m     fsdp:
[36m(Runner pid=111972)[0m       enable_cpu_offload: false
[36m(Runner pid=111972)[0m       enable_full_shard: true
[36m(Runner pid=111972)[0m       enable_rank0_init: true
[36m(Runner pid=111972)[0m       fsdp_size: -1
[36m(Runner pid=111972)[0m       mp_buffer_dtype: fp32
[36m(Runner pid=111972)[0m       mp_param_dtype: bf16
[36m(Runner pid=111972)[0m       mp_reduce_dtype: fp32
[36m(Runner pid=111972)[0m       torch_dtype: null
[36m(Runner pid=111972)[0m       use_orig_params: false
[36m(Runner pid=111972)[0m     global_batch_size: 256
[36m(Runner pid=111972)[0m     global_batch_size_per_device: -1
[36m(Runner pid=111972)[0m     loss_avg_mode: token
[36m(Runner pid=111972)[0m     max_grad_norm: 1.0
[36m(Runner pid=111972)[0m     micro_batch_size_per_device_for_experience: 16
[36m(Runner pid=111972)[0m     micro_batch_size_per_device_for_update: 4
[36m(Runner pid=111972)[0m     model:
[36m(Runner pid=111972)[0m       enable_gradient_checkpointing: true
[36m(Runner pid=111972)[0m       freeze_vision_tower: false
[36m(Runner pid=111972)[0m       model_path: null
[36m(Runner pid=111972)[0m       override_config: {}
[36m(Runner pid=111972)[0m       tokenizer_path: null
[36m(Runner pid=111972)[0m       trust_remote_code: true
[36m(Runner pid=111972)[0m     offload:
[36m(Runner pid=111972)[0m       offload_optimizer: false
[36m(Runner pid=111972)[0m       offload_params: false
[36m(Runner pid=111972)[0m     optim:
[36m(Runner pid=111972)[0m       betas:
[36m(Runner pid=111972)[0m       - 0.9
[36m(Runner pid=111972)[0m       - 0.999
[36m(Runner pid=111972)[0m       lr: 1.0e-06
[36m(Runner pid=111972)[0m       lr_warmup_ratio: 0.0
[36m(Runner pid=111972)[0m       lr_warmup_steps: null
[36m(Runner pid=111972)[0m       min_lr_ratio: null
[36m(Runner pid=111972)[0m       strategy: adamw
[36m(Runner pid=111972)[0m       training_steps: 60
[36m(Runner pid=111972)[0m       warmup_style: constant
[36m(Runner pid=111972)[0m       weight_decay: 0.01
[36m(Runner pid=111972)[0m     padding_free: false
[36m(Runner pid=111972)[0m     ppo_epochs: 1
[36m(Runner pid=111972)[0m     strategy: fsdp
[36m(Runner pid=111972)[0m     ulysses_size: 1
[36m(Runner pid=111972)[0m   hybrid_engine: true
[36m(Runner pid=111972)[0m   ref:
[36m(Runner pid=111972)[0m     fsdp:
[36m(Runner pid=111972)[0m       enable_cpu_offload: true
[36m(Runner pid=111972)[0m       enable_full_shard: true
[36m(Runner pid=111972)[0m       enable_rank0_init: true
[36m(Runner pid=111972)[0m       fsdp_size: -1
[36m(Runner pid=111972)[0m       mp_buffer_dtype: fp32
[36m(Runner pid=111972)[0m       mp_param_dtype: bf16
[36m(Runner pid=111972)[0m       mp_reduce_dtype: fp32
[36m(Runner pid=111972)[0m       torch_dtype: null
[36m(Runner pid=111972)[0m       use_orig_params: false
[36m(Runner pid=111972)[0m     micro_batch_size_per_device_for_experience: 16
[36m(Runner pid=111972)[0m     offload:
[36m(Runner pid=111972)[0m       offload_optimizer: false
[36m(Runner pid=111972)[0m       offload_params: false
[36m(Runner pid=111972)[0m     padding_free: true
[36m(Runner pid=111972)[0m     strategy: fsdp
[36m(Runner pid=111972)[0m     ulysses_size: 1
[36m(Runner pid=111972)[0m     use_torch_compile: true
[36m(Runner pid=111972)[0m   reward:
[36m(Runner pid=111972)[0m     num_cpus: 1
[36m(Runner pid=111972)[0m     reward_function: /root/EasyR1/examples/reward_function/math.py
[36m(Runner pid=111972)[0m     reward_function_kwargs: {}
[36m(Runner pid=111972)[0m     reward_function_name: compute_score
[36m(Runner pid=111972)[0m     reward_type: batch
[36m(Runner pid=111972)[0m     skip_special_tokens: true
[36m(Runner pid=111972)[0m   rollout:
[36m(Runner pid=111972)[0m     disable_log_stats: true
[36m(Runner pid=111972)[0m     disable_tqdm: false
[36m(Runner pid=111972)[0m     dtype: bf16
[36m(Runner pid=111972)[0m     enable_chunked_prefill: false
[36m(Runner pid=111972)[0m     enforce_eager: false
[36m(Runner pid=111972)[0m     gpu_memory_utilization: 0.6
[36m(Runner pid=111972)[0m     ignore_eos: false
[36m(Runner pid=111972)[0m     limit_images: 0
[36m(Runner pid=111972)[0m     max_model_len: null
[36m(Runner pid=111972)[0m     max_num_batched_tokens: 8192
[36m(Runner pid=111972)[0m     n: 5
[36m(Runner pid=111972)[0m     name: vllm
[36m(Runner pid=111972)[0m     prompt_length: 2048
[36m(Runner pid=111972)[0m     response_length: 2048
[36m(Runner pid=111972)[0m     seed: 1
[36m(Runner pid=111972)[0m     temperature: 1.0
[36m(Runner pid=111972)[0m     tensor_parallel_size: 1
[36m(Runner pid=111972)[0m     top_k: -1
[36m(Runner pid=111972)[0m     top_p: 0.99
[36m(Runner pid=111972)[0m     trust_remote_code: false
[36m(Runner pid=111972)[0m     val_override_config:
[36m(Runner pid=111972)[0m       n: 1
[36m(Runner pid=111972)[0m       temperature: 0.5
[36m(Runner pid=111972)[0m 
[36m(Runner pid=111972)[0m Start validation...
[36m(WorkerDict pid=114974)[0m Before vllm wake up in sharding manager: 1.61 GB / 23.53 GB.
[36m(WorkerDict pid=115355)[0m Sampling params: {'max_tokens': 2048, 'detokenize': False, 'logit_bias': {151655: -100}, 'n': 5, 'temperature': 1.0, 'top_p': 0.99, 'top_k': -1, 'seed': 1, 'ignore_eos': False}.
